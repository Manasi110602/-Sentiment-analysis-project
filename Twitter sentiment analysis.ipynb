{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5960f86f-8e71-42d7-913d-d04ecfa2a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB , BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04898c86-81a1-4f3c-845b-6ca1d86a7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Zeel\n",
      "[nltk_data]     soni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Zeel\n",
      "[nltk_data]     soni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Zeel\n",
      "[nltk_data]     soni\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure you have downloaded the necessary NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb73a367-f803-4300-b16a-ca6dd86a2e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       when modi promised “minimum government maximum...      -1.0\n",
       "1       talk all the nonsense and continue all the dra...       0.0\n",
       "2       what did just say vote for modi  welcome bjp t...       1.0\n",
       "3       asking his supporters prefix chowkidar their n...       1.0\n",
       "4       answer who among these the most powerful world...       1.0\n",
       "...                                                   ...       ...\n",
       "162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
       "162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
       "162977  did you cover her interaction forum where she ...       0.0\n",
       "162978  there big project came into india modi dream p...       0.0\n",
       "162979  have you ever listen about like gurukul where ...       1.0\n",
       "\n",
       "[162980 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Twitter_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d073720-bd7d-4e8f-9afe-d423da1d3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5c443-f1bf-4ee6-92a9-647c4d188087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2a8583-3243-4126-b0ac-33c3637d0617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeel soni\\AppData\\Local\\Temp\\ipykernel_16540\\3877369450.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_text'] = df['clean_text'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Convert text to lowercase\n",
    "df['clean_text'] = df['clean_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bf567c-bc27-415f-8f4a-b35543c378d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeel soni\\AppData\\Local\\Temp\\ipykernel_16540\\4233730392.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['clean_text'].apply(word_tokenize)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "df['tokens'] = df['clean_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e98c3e68-4cc8-435d-8773-c8d2859c2cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeel soni\\AppData\\Local\\Temp\\ipykernel_16540\\2416314447.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n"
     ]
    }
   ],
   "source": [
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stop words\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b2fe36-4ca8-4e19-826e-9081937ec080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeel soni\\AppData\\Local\\Temp\\ipykernel_16540\\1438822294.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fdac49-bfb9-46d9-8e20-c5013a8504d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeel soni\\AppData\\Local\\Temp\\ipykernel_16540\\1438822294.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82589620-e40e-4732-8b26-f9a219d4be7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeel soni\\AppData\\Local\\Temp\\ipykernel_16540\\68334516.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = df['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3c7ff5-d7e2-4ed9-984d-a537add5201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db23465f-2015-4467-b866-cbb6cad8d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fa70808-8bf9-49f0-bff6-84b3affe824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698325e5-fdc1-42af-b745-bef29afdc23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bdc87b6-8ae0-44a6-bcdb-d4f9951cf302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Results\n",
      "Accuracy: 0.6368963612934896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.81      0.35      0.48      7152\n",
      "         0.0       0.83      0.43      0.57     11067\n",
      "         1.0       0.57      0.94      0.71     14375\n",
      "\n",
      "    accuracy                           0.64     32594\n",
      "   macro avg       0.74      0.57      0.59     32594\n",
      "weighted avg       0.71      0.64      0.61     32594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training using CountVectorizer\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_counts, y_train)\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Results\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_tfidf)}')\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3213737-b93c-40f3-963d-977b4f072ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Results\n",
      "Accuracy: 0.5717616739277167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.12      0.22      7152\n",
      "         0.0       0.88      0.33      0.48     11067\n",
      "         1.0       0.51      0.98      0.67     14375\n",
      "\n",
      "    accuracy                           0.57     32594\n",
      "   macro avg       0.77      0.48      0.46     32594\n",
      "weighted avg       0.73      0.57      0.51     32594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training using TF-IDF\n",
    "tfidf = MultinomialNB()\n",
    "tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Results\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_tfidf)}')\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94a3b571-a554-4075-8e39-5ce455f81d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Results\n",
      "Accuracy: 0.7546174142480211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.71      0.46      0.56      7152\n",
      "         0.0       0.79      0.82      0.80     11067\n",
      "         1.0       0.74      0.86      0.79     14375\n",
      "\n",
      "    accuracy                           0.75     32594\n",
      "   macro avg       0.75      0.71      0.72     32594\n",
      "weighted avg       0.75      0.75      0.75     32594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training using CountVectorizer\n",
    "nb_counts = BernoulliNB()\n",
    "nb_counts.fit(X_train_counts, y_train)\n",
    "y_pred_counts = nb_counts.predict(X_test_counts)\n",
    "print(\"CountVectorizer Results\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_counts)}')\n",
    "print(classification_report(y_test, y_pred_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fa3866e-21d9-4416-a70b-a7272cf260ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1. -1. ...  0. -1.  0.]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(nb_counts,'bnb.joblib')\n",
    "\n",
    "loaded_model=joblib.load('bnb.joblib')\n",
    "\n",
    "print(loaded_model.predict(X_test_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f8c6a-3c47-419c-9a44-d8d5053f54e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1f032-0e9f-4e4f-8983-a8f8f647274d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12845195-0aaa-42d5-8b3e-85b87de31d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c1f9b-1a01-4125-ae23-7af12ac45801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61e9eb-d2ec-4bdf-b631-d0826f2f4366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
